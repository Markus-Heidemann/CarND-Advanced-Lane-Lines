{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Import video tools\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "class NamedImage:\n",
    "    img = np.empty([0,0,0])\n",
    "    name = ''\n",
    "    \n",
    "    def __init__(self, img, name):\n",
    "        self.img = img\n",
    "        self.name = name\n",
    "\n",
    "def plot_multiple(plot_img_list):\n",
    "    ncol = 2\n",
    "    nrow = int(np.ceil(len(plot_img_list)/ncol))\n",
    "\n",
    "    f, axes = plt.subplots(nrow, ncol, figsize=(96,36), squeeze=False)\n",
    "    f.tight_layout()\n",
    "\n",
    "    for idx, named_img in enumerate(plot_img_list):\n",
    "        selected_row = int(idx / ncol)\n",
    "        selected_col = int(idx % ncol)\n",
    "        axes[selected_row, selected_col].imshow(named_img.img)\n",
    "        axes[selected_row, selected_col].set_title(named_img.name, fontsize=14)\n",
    "        \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0., wspace=0.)\n",
    "\n",
    "# Gaussian Blur\n",
    "def gaussian_smoothing(img, kernel_size=3):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "# ROI Mask\n",
    "def binary_mask(img, vertices):\n",
    "    mask = np.zeros_like(img)   \n",
    "\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def combine_img(init_img, img, alpha=0.8, beta=1., gamma=0.):\n",
    "    return cv2.addWeighted(init_img, alpha, img, beta, gamma)\n",
    "\n",
    "class Line():\n",
    "    def __init__(self, coeffs=np.array([0,0,0]), valid=True, x_pix=None, y_pix=None):\n",
    "        self.coeffs = coeffs\n",
    "        self.x_pix = x_pix\n",
    "        self.y_pix = y_pix\n",
    "        self.valid = True\n",
    "        \n",
    "    def radius_pix(self, y_eval):\n",
    "        return ((1 + (2*self.coeffs[0]*y_eval \\\n",
    "                      + self.coeffs[1])**2)**(1.5)) \\\n",
    "                      / np.absolute(2*self.coeffs[0])\n",
    "        \n",
    "    def radius_m(self, y_eval=720, ym_per_pix=(30/720), xm_per_pix=(3.7/700)):\n",
    "        return ((1 + (2*self.coeffs[0]*y_eval*ym_per_pix \\\n",
    "                      + self.coeffs[1])**2)**1.5) \\\n",
    "                      / np.absolute(2*self.coeffs[0])\n",
    "        \n",
    "    def f(self, y_eval):\n",
    "        return self.coeffs[0]*y_eval**2 + self.coeffs[1]*y_eval + self.coeffs[2]\n",
    "\n",
    "class LineHist():\n",
    "    def __init__(self, histSize= 5):\n",
    "        self.histSize = histSize\n",
    "        self.hist_left = deque([Line(valid=False)], maxlen=histSize)\n",
    "        self.hist_right = deque([Line(valid=False)], maxlen=histSize)\n",
    "        \n",
    "    def appendLines(self, line_left, line_right, curvature_thresh=0.05):\n",
    "        if self.sanityCheck(line_left, line_right, curvature_thresh):\n",
    "            self.hist_left.appendleft(line_left)\n",
    "            self.hist_right.appendleft(line_right)\n",
    "        else:\n",
    "            self.hist_left.appendleft(Line(valid=False))\n",
    "            self.hist_right.appendleft(Line(valid=False))\n",
    "        \n",
    "    def sanityCheck(self,\n",
    "                    line_left,\n",
    "                    line_right,\n",
    "                    curvature_thresh=0.05,\n",
    "                    dist_thresh=(1.5, 2.5),\n",
    "                    var_thresh=1.0,\n",
    "                    img_height=720,\n",
    "                    xm_per_pix=(3.7/700)):\n",
    "        \n",
    "        checkResult = True\n",
    "        \n",
    "        # check if the lines have similar curvature\n",
    "        left_rad = line_left.radius_m()\n",
    "        right_rad = line_right.radius_m()\n",
    "        if not (np.absolute(left_rad - right_rad) / left_rad) <= curvature_thresh:\n",
    "            checkResult = False\n",
    "            \n",
    "        # check if the lines fit to the current average line\n",
    "        avgLineRad = self.getAverageMiddleLine().radius_m()\n",
    "        if not (((np.absolute(left_rad - avgLineRad) / left_rad) <= curvature_thresh) \\\n",
    "            & ((np.absolute(right_rad - avgLineRad) / right_rad) <= curvature_thresh)):\n",
    "            checkResult = False\n",
    "            \n",
    "        # check if average distance between the lines is ok\n",
    "        dist_vect = xm_per_pix * line_left.f(np.linspace(0, img_height-1, img_height)) \\\n",
    "                                        - line_right.f(np.linspace(0, img_height-1, img_height))\n",
    "        mean_dist = np.mean(dist_vect)    \n",
    "        if (mean_dist > dist_thresh[1]) | (mean_dist < dist_thresh[0]):\n",
    "            checkResult = False\n",
    "        \n",
    "        # check if the lines are parallel\n",
    "        dist_variance = np.var(dist_vect)\n",
    "        if dist_variance > var_thresh:\n",
    "            checkResult = False\n",
    "        \n",
    "        return checkResult\n",
    "        \n",
    "    def getAverageMiddleLine(self):\n",
    "        coeff_avg = []\n",
    "        for line in self.hist_left:\n",
    "            if line.valid:\n",
    "                coeff_avg = np.append(coeff_avg, line.coeffs)\n",
    "        for line in self.hist_right:\n",
    "            if line.valid:\n",
    "                coeff_avg = np.append(coeff_avg, line.coeffs)\n",
    "\n",
    "        coeff_avg = np.vstack(coeff_avg)\n",
    "        return Line(np.mean(coeff_avg, axis=1))\n",
    "    \n",
    "    def getAverageLines(self):\n",
    "        coeff_avg_left = np.array([])\n",
    "        coeff_avg_right = np.array([])\n",
    "        \n",
    "        for line in self.hist_left:\n",
    "            if line.valid:\n",
    "                coeff_avg_left = np.append(coeff_avg_left, line.coeffs)\n",
    "        coeff_avg_left = np.vstack(coeff_avg_left)\n",
    "        left_line = Line(np.mean(coeff_avg_left, axis=1))\n",
    "        \n",
    "        for line in self.hist_right:\n",
    "            if line.valid:\n",
    "                coeff_avg_right = np.append(coeff_avg_right, line.coeffs)\n",
    "        coeff_avg_right = np.vstack(coeff_avg_right)\n",
    "        right_line = Line(np.mean(coeff_avg_right, axis=1))\n",
    "        \n",
    "        return left_line, right_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of corners in x and y direction\n",
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "def cal_get_calib_params():\n",
    "    cal_img_path = \"./camera_cal\"        \n",
    "    img_points = []\n",
    "    obj_points = []\n",
    "\n",
    "    # Object points\n",
    "    objp_template = np.zeros((nx*ny, 3), np.float32)\n",
    "    objp_template[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "        \n",
    "    for imgName in os.listdir(cal_img_path):\n",
    "        #load the image\n",
    "        img = cv2.imread(os.path.join(cal_img_path, imgName))\n",
    "        # convert ot grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "        \n",
    "        if ret == True:\n",
    "            img_points.append(corners)\n",
    "            obj_points.append(objp_template)\n",
    "    return img_points, obj_points\n",
    "        \n",
    "def cal_undistort(img_points, obj_points, img):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, img.shape[1::-1], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Space Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cst_threshold(img, channel='S', thresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    if channel == 'H':\n",
    "        single_channel = hls[:,:,0]\n",
    "    elif channel == 'L':\n",
    "        single_channel = hls[:,:,1]\n",
    "    elif channel == 'S':\n",
    "        single_channel = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(single_channel)\n",
    "    binary_output[(single_channel > thresh[0]) & (single_channel <= thresh[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_mag_thresh(img, sobel_kernel=5, thresh=(0, 255)):\n",
    "    # if the image is a color image, then first convert it to gray\n",
    "    if len(img.shape) > 1:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # calculate the gradient magnitude\n",
    "    mag = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    # scale to a range between 0 and 255\n",
    "    scaled_sobel = np.uint8(255*mag/np.max(mag))\n",
    "    \n",
    "    # apply the threshold and create a binary output image\n",
    "    binary = np.zeros_like(scaled_sobel)\n",
    "    binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_dir_thresh(img, sobel_kernel=5, thresh=(0, np.pi/2)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    sobelx_abs = np.absolute(sobelx)\n",
    "    sobely_abs = np.absolute(sobely)\n",
    "\n",
    "    directions = np.arctan2(sobely_abs, sobelx_abs)\n",
    "\n",
    "    binary = np.zeros_like(directions)\n",
    "    binary[(directions >= thresh[0]) & (directions <= thresh[1])] = 1\n",
    "\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for thresholded binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration\n",
    "img_points, obj_points = cal_get_calib_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_segmentation(img):\n",
    "    # Array of images, which is used to store the intermediate results of the pipeline\n",
    "    plot_img_list = []\n",
    "\n",
    "    #### Parameters ####\n",
    "    # Color thresholds\n",
    "    thresh_cst_h = (90,100)\n",
    "    thresh_cst_l = (200,255)\n",
    "    thresh_cst_s = (150,255)\n",
    "\n",
    "    # Gradient thresholds\n",
    "    # Magnitude\n",
    "    thresh_grad_mag = (100,150)\n",
    "    # Direction\n",
    "    thresh_grad_dir = (0.7,1.3)\n",
    "\n",
    "    # Vertices of ROI mask\n",
    "    x_len = img.shape[1]\n",
    "    y_len = img.shape[0]\n",
    "    vertices = np.array([[[0,y_len],\n",
    "                [int(x_len/2)-30,int(y_len/2)+70],\n",
    "                [int(x_len/2)+30,int(y_len/2)+70],\n",
    "                [x_len,y_len]]])\n",
    "\n",
    "    img_undist = cal_undistort(img_points, obj_points, img)\n",
    "    plot_img_list.append(NamedImage(img_undist, 'Undistortion'))\n",
    "\n",
    "    img_undist = gaussian_smoothing(img, kernel_size=5)\n",
    "\n",
    "    img_color_thresh_H = cst_threshold(img_undist, 'H', thresh_cst_h)\n",
    "    plot_img_list.append(NamedImage(img_color_thresh_H, 'Color Threshold H'))\n",
    "\n",
    "    img_color_thresh_L = cst_threshold(img_undist, 'L', thresh_cst_l)\n",
    "    plot_img_list.append(NamedImage(img_color_thresh_L, 'Color Threshold L'))\n",
    "\n",
    "    img_color_thresh_S = cst_threshold(img_undist, 'S', thresh_cst_s)\n",
    "    plot_img_list.append(NamedImage(img_color_thresh_S, 'Color Threshold S'))\n",
    "\n",
    "    img_grad_mag = grad_mag_thresh(img_undist, 5, thresh_grad_mag)\n",
    "    plot_img_list.append(NamedImage(img_grad_mag, 'Gradient Magnitude Threshold'))\n",
    "\n",
    "    img_grad_dir = grad_dir_thresh(img_undist, sobel_kernel=5, thresh=thresh_grad_dir)\n",
    "    plot_img_list.append(NamedImage(img_grad_dir, 'Gradient Direction Threshold'))\n",
    "\n",
    "    combined_grad = np.zeros_like(img_grad_dir)\n",
    "    combined_grad[((img_grad_mag == 1) & (img_grad_dir == 1))] = 1\n",
    "    plot_img_list.append(NamedImage(combined_grad, 'Combined Gradient Thresholds'))\n",
    "\n",
    "    combined_col = np.zeros_like(img_color_thresh_H)\n",
    "    combined_col[((img_color_thresh_H == 1) | (img_color_thresh_L == 1) | (img_color_thresh_S == 1))] = 1\n",
    "    plot_img_list.append(NamedImage(combined_col, 'Combined Color Thresholds'))\n",
    "\n",
    "    combined = np.zeros_like(img_color_thresh_H)\n",
    "    combined[((combined_grad == 1) | (combined_col == 1))] = 1\n",
    "    plot_img_list.append(NamedImage(combined, 'All Thresholds Combined'))\n",
    "\n",
    "    img_masked = binary_mask(combined, vertices)\n",
    "    plot_img_list.append(NamedImage(img_masked, 'ROI Mask Applied'))\n",
    "\n",
    "    return img_masked, plot_img_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(img, inverse=False):\n",
    "    x_len = img.shape[1]\n",
    "    y_len = img.shape[0]\n",
    "    \n",
    "    src = np.float32([[200,y_len],\n",
    "                      [595,450],\n",
    "                      [686,450],\n",
    "                      [1105,y_len]])\n",
    "    dst = np.float32([[400,y_len],\n",
    "                      [400,0],\n",
    "                      [880,0],\n",
    "                      [880,y_len]])\n",
    "    \n",
    "    #plt.imshow(img)\n",
    "    #plt.plot(src[0][0],src[0][1], '.')\n",
    "    #plt.plot(src[1][0],src[1][1], '.')\n",
    "    #plt.plot(src[2][0],src[2][1], '.')\n",
    "    #plt.plot(src[3][0],src[3][1], '.')\n",
    "    \n",
    "    # in case we want to get the inverse transform, swap src and dst\n",
    "    if inverse:\n",
    "        src,dst = dst,src\n",
    "        \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(img, M, img.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped, M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_init_line_pos(img):\n",
    "    bottom_half = img[img.shape[0]//2:, :]\n",
    "\n",
    "    hist = np.sum(bottom_half, axis = 0)\n",
    "\n",
    "    middle = np.int(hist.shape[0]//2)\n",
    "    \n",
    "    x_left = np.argmax(hist[:middle])\n",
    "    x_right = np.argmax(hist[middle:]) + middle\n",
    "    \n",
    "    return x_left, x_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lines_sliding_win(img, x_init_left, x_init_right):\n",
    "    \n",
    "    out_img = np.dstack((img*255, img*255, img*255))\n",
    "    \n",
    "    num_windows = 9\n",
    "    win_width = 100\n",
    "    min_pix = 50\n",
    "    \n",
    "    win_height = np.int(img.shape[0]//num_windows)\n",
    "    \n",
    "    nonzero = img.nonzero()\n",
    "    nonzero_x = nonzero[1]\n",
    "    nonzero_y = nonzero[0]\n",
    "    \n",
    "    x_current_left = x_init_left\n",
    "    x_current_right = x_init_right\n",
    "    \n",
    "    idx_line_left = []\n",
    "    idx_line_right = []\n",
    "    \n",
    "    for win in range(num_windows):\n",
    "        y_low = img.shape[0] - ((win + 1) * win_height)\n",
    "        y_high = img.shape[0] - (win * win_height)\n",
    "        \n",
    "        x_low_left = x_current_left - win_width\n",
    "        x_high_left = x_current_left + win_width\n",
    "        x_low_right = x_current_right - win_width\n",
    "        x_high_right = x_current_right + win_width\n",
    "        \n",
    "\n",
    "        cv2.rectangle(out_img, (x_low_left, y_low), (x_high_left, y_high), (0,255,0), 5)\n",
    "        cv2.rectangle(out_img, (x_low_right, y_low), (x_high_right, y_high), (0,255,0), 5)\n",
    "        \n",
    "        matching_idx_left = ((nonzero_y >= y_low) & (nonzero_y < y_high) & \\\n",
    "                             (nonzero_x >= x_low_left) & (nonzero_x < x_high_left)).nonzero()[0]\n",
    "        matching_idx_right = ((nonzero_y >= y_low) & (nonzero_y < y_high) & \\\n",
    "                              (nonzero_x >= x_low_right) & (nonzero_x < x_high_right)).nonzero()[0]\n",
    "        \n",
    "        idx_line_left.append(matching_idx_left)\n",
    "        idx_line_right.append(matching_idx_right)\n",
    "        \n",
    "        if len(matching_idx_left) > min_pix:\n",
    "            x_current_left = np.int(np.mean(nonzero_x[matching_idx_left]))\n",
    "        if len(matching_idx_right) > min_pix:\n",
    "            x_current_right = np.int(np.mean(nonzero_x[matching_idx_right]))\n",
    "            \n",
    "    idx_line_left = np.concatenate(idx_line_left)\n",
    "    idx_line_right = np.concatenate(idx_line_right)\n",
    "    \n",
    "    x_left = nonzero_x[idx_line_left]\n",
    "    y_left = nonzero_y[idx_line_left]\n",
    "    x_right = nonzero_x[idx_line_right]\n",
    "    y_right = nonzero_y[idx_line_right]\n",
    "    \n",
    "    return x_left, y_left, x_right, y_right, out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_polynomial(img):\n",
    "    \n",
    "    # Find the starting positions for the window search\n",
    "    x_init_left, x_init_right = find_init_line_pos(img)\n",
    "    \n",
    "    # Search the lines with sliding windows\n",
    "    x_left, y_left, x_right, y_right, out_img_rect = find_lines_sliding_win(img, x_init_left, x_init_right)\n",
    "    \n",
    "    # Fit a second order polynomial through the marked pixels\n",
    "    line_left = Line(np.polyfit(y_left, x_left, 2), x_left, y_left)\n",
    "    line_right = Line(np.polyfit(y_right, x_right, 2), x_right, y_right)\n",
    "    \n",
    "    out_img_rect[y_left, x_left] = [255,0,0]\n",
    "    out_img_rect[y_right, x_right] = [0,0,255]\n",
    "    \n",
    "    out_img = np.zeros_like(out_img_rect)\n",
    "    out_img[y_left, x_left] = [255,0,0]\n",
    "    out_img[y_right, x_right] = [0,0,255]\n",
    "    \n",
    "    return out_img, out_img_rect, line_left, line_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lane_area(img_shape, line_left, line_right):\n",
    "    lane_area = np.zeros(img_shape)\n",
    "    \n",
    "    y_plot = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    x_plot_left = line_left.f(y_plot)\n",
    "    x_plot_right = line_right.f(y_plot)\n",
    "    \n",
    "    for row in range(img_shape[0]):\n",
    "        for col in range(img_shape[1]):\n",
    "            if (x_plot_left[row] <= col) & (col <= x_plot_right[row]):\n",
    "                lane_area[row, col] = [0,255,0]\n",
    "                \n",
    "    return lane_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Segment the lane lines and get a binary image\n",
    "    binary, _ = line_segmentation(img)\n",
    "\n",
    "    # Warp the image to birdseye view\n",
    "    warped, _ = perspective_transform(binary)\n",
    "\n",
    "    # Fit polynomials through the lane lines\n",
    "    img_poly_fit, _, line_left, line_right = fit_polynomial(warped)\n",
    "    \n",
    "    ###############\n",
    "    ### DRAWING ###\n",
    "    ###############\n",
    "    \n",
    "    # Unwarp the image, that marks the lane lines\n",
    "    unwarped_lines, _ = perspective_transform(img_poly_fit, inverse=True)\n",
    "    # Unwarp the image, that marks the lane area\n",
    "    img_lane_area = draw_lane_area(img.shape, line_left, line_right)\n",
    "    unwarped_area, _ = perspective_transform(img_lane_area, inverse=True)\n",
    "\n",
    "    # Combine the results with the original image\n",
    "    img = combine_img(img, unwarped_area, alpha=0.8, beta=.5, gamma=0.)\n",
    "    img[unwarped_lines[:,:,0] == 255] = [255,0,0]\n",
    "    img[unwarped_lines[:,:,2] == 255] = [0,0,255]\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    plt.text(100,100,str(line_left.radius_m(img.shape[0])),withdash=True)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgProcessor():\n",
    "    def __init__(self):\n",
    "        self.lineHist = LineHist()\n",
    "        \n",
    "    def process_image(self, img):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Segment the lane lines and get a binary image\n",
    "        binary, _ = line_segmentation(img)\n",
    "\n",
    "        # Warp the image to birdseye view\n",
    "        warped, _ = perspective_transform(binary)\n",
    "\n",
    "        # Fit polynomials through the lane lines\n",
    "        img_poly_fit, _, line_left, line_right = fit_polynomial(warped)\n",
    "        \n",
    "        self.lineHist.appendLines(line_left, line_right)\n",
    "\n",
    "        line_left, line_right = self.lineHist.getAverageLines()\n",
    "        \n",
    "        ###############\n",
    "        ### DRAWING ###\n",
    "        ###############\n",
    "        \n",
    "        # Unwarp the image, that marks the lane lines\n",
    "        unwarped_lines, _ = perspective_transform(img_poly_fit, inverse=True)\n",
    "        # Unwarp the image, that marks the lane area\n",
    "        img_lane_area = draw_lane_area(img.shape, line_left, line_right)\n",
    "        unwarped_area, _ = perspective_transform(img_lane_area, inverse=True)\n",
    "        plt.imshow(img_lane_area)\n",
    "\n",
    "        print(type(img))\n",
    "        print(type(unwarped_area))\n",
    "        \n",
    "        # Combine the results with the original image\n",
    "        img = combine_img(img, unwarped_area, alpha=0.8, beta=.5, gamma=0.)\n",
    "        img[unwarped_lines[:,:,0] == 255] = [255,0,0]\n",
    "        img[unwarped_lines[:,:,2] == 255] = [0,0,255]\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        plt.text(100,100,str(line_left.radius_m(img.shape[0])),withdash=True)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/feedstock_root/build_artefacts/opencv_1496434080029/work/opencv-3.2.0/modules/core/src/arithm.cpp:683: error: (-5) When the input arrays in add/subtract/multiply/divide functions have different types, the output array type must be explicitly specified in function arithm_op\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-ad46e48bef8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-110-ad46e48bef8d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# load test image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_images/test2.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-e52d76902e18>\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Combine the results with the original image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munwarped_area\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munwarped_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munwarped_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-97a37c723092>\u001b[0m in \u001b[0;36mcombine_img\u001b[0;34m(init_img, img, alpha, beta, gamma)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcombine_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddWeighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /feedstock_root/build_artefacts/opencv_1496434080029/work/opencv-3.2.0/modules/core/src/arithm.cpp:683: error: (-5) When the input arrays in add/subtract/multiply/divide functions have different types, the output array type must be explicitly specified in function arithm_op\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8dc6cf7710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    img_proc = ImgProcessor()\n",
    "    # load test image\n",
    "    img = cv2.imread('test_images/test2.jpg')\n",
    "    img = img_proc.process_image(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_output = './output_video/project_video.mp4'\n",
    "clip1 = VideoFileClip(\"./project_video.mp4\").subclip(0,5)\n",
    "video_clip = clip1.fl_image(process_image)\n",
    "%time video_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
