{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Import video tools\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "class NamedImage:\n",
    "    img = np.empty([0,0,0])\n",
    "    name = ''\n",
    "    \n",
    "    def __init__(self, img, name):\n",
    "        self.img = img\n",
    "        self.name = name\n",
    "\n",
    "def plot_multiple(plot_img_list):\n",
    "    ncol = 2\n",
    "    nrow = int(np.ceil(len(plot_img_list)/ncol))\n",
    "\n",
    "    f, axes = plt.subplots(nrow, ncol, figsize=(96,36), squeeze=False)\n",
    "    f.tight_layout()\n",
    "\n",
    "    for idx, named_img in enumerate(plot_img_list):\n",
    "        selected_row = int(idx / ncol)\n",
    "        selected_col = int(idx % ncol)\n",
    "        axes[selected_row, selected_col].imshow(named_img.img)\n",
    "        axes[selected_row, selected_col].set_title(named_img.name, fontsize=14)\n",
    "        \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0., wspace=0.)\n",
    "\n",
    "# Gaussian Blur\n",
    "def gaussian_smoothing(img, kernel_size=3):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "# ROI Mask\n",
    "def binary_mask(img, vertices):\n",
    "    mask = np.zeros_like(img)   \n",
    "\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def combine_img(init_img, img, alpha=0.8, beta=1., gamma=0.):\n",
    "    return cv2.addWeighted(init_img, alpha, img, beta, gamma)\n",
    "\n",
    "class Line():\n",
    "    def __init__(self, coeffs=np.array([0,0,0]), valid=True, x_pix=None, y_pix=None):\n",
    "        self.coeffs = coeffs\n",
    "        self.valid = valid\n",
    "        self.x_pix = x_pix\n",
    "        self.y_pix = y_pix\n",
    "        \n",
    "    def radius_pix(self, y_eval):\n",
    "        return ((1 + (2*self.coeffs[0]*y_eval \\\n",
    "                      + self.coeffs[1])**2)**(1.5)) \\\n",
    "                      / np.absolute(2*self.coeffs[0])\n",
    "        \n",
    "    def radius_m(self, y_eval=720, ym_per_pix=(30/720), xm_per_pix=(3.7/700)):\n",
    "        return ((1 + (2*self.coeffs[0]*y_eval*ym_per_pix \\\n",
    "                      + self.coeffs[1])**2)**1.5) \\\n",
    "                      / np.absolute(2*self.coeffs[0])\n",
    "        \n",
    "    def f(self, y_eval):\n",
    "        return self.coeffs[0]*y_eval**2 + self.coeffs[1]*y_eval + self.coeffs[2]\n",
    "\n",
    "class LineHist():\n",
    "    def __init__(self, histSize= 5):\n",
    "        self.histSize = histSize\n",
    "        self.hist_left = deque([Line(valid=False)], maxlen=histSize)\n",
    "        self.hist_right = deque([Line(valid=False)], maxlen=histSize)\n",
    "        \n",
    "    def appendLines(self, line_left, line_right, curvature_thresh=0.05):\n",
    "        print(\"Called appendLines()\")\n",
    "        if self.sanityCheck(line_left, line_right, curvature_thresh):\n",
    "            print(\"sanityCheck passed\")\n",
    "            self.hist_left.appendleft(line_left)\n",
    "            self.hist_right.appendleft(line_right)\n",
    "        else:\n",
    "            print(\"sanityCheck failed\")\n",
    "            self.hist_left.appendleft(Line(valid=False))\n",
    "            self.hist_right.appendleft(Line(valid=False))\n",
    "        \n",
    "    def sanityCheck(self,\n",
    "                    line_left,\n",
    "                    line_right,\n",
    "                    curvature_thresh=0.05,\n",
    "                    dist_thresh=(1.5, 2.5),\n",
    "                    var_thresh=1.0,\n",
    "                    img_height=720,\n",
    "                    xm_per_pix=(3.7/700)):\n",
    "        \n",
    "        checkResult = True\n",
    "        \n",
    "        # check if the lines have similar curvature\n",
    "        left_rad = line_left.radius_m()\n",
    "        right_rad = line_right.radius_m()\n",
    "        if not (np.absolute(left_rad - right_rad) / left_rad) <= curvature_thresh:\n",
    "            checkResult = False\n",
    "            \n",
    "        # check if average distance between the lines is ok\n",
    "        dist_vect = xm_per_pix * line_left.f(np.linspace(0, img_height-1, img_height)) \\\n",
    "                                        - line_right.f(np.linspace(0, img_height-1, img_height))\n",
    "        mean_dist = np.mean(dist_vect)    \n",
    "        if (mean_dist > dist_thresh[1]) | (mean_dist < dist_thresh[0]):\n",
    "            checkResult = False\n",
    "        \n",
    "        # check if the lines are parallel\n",
    "        dist_variance = np.var(dist_vect)\n",
    "        if dist_variance > var_thresh:\n",
    "            checkResult = False\n",
    "            \n",
    "        # check if the lines fit to the current average line\n",
    "        validLineInHist = False\n",
    "        for line in self.hist_left:\n",
    "            validLineInHist = validLineInHist | line.valid\n",
    "        if validLineInHist:\n",
    "            avgLineRad = self.getAverageMiddleLine().radius_m()\n",
    "            if not (((np.absolute(left_rad - avgLineRad) / left_rad) <= curvature_thresh) \\\n",
    "                & ((np.absolute(right_rad - avgLineRad) / right_rad) <= curvature_thresh)):\n",
    "                checkResult = False\n",
    "        \n",
    "        return checkResult\n",
    "        \n",
    "    def getAverageMiddleLine(self):\n",
    "        coeff_avg = np.array([])\n",
    "        for line in self.hist_left:\n",
    "            if line.valid:\n",
    "                coeff_avg = np.append(coeff_avg, line.coeffs)\n",
    "        for line in self.hist_right:\n",
    "            if line.valid:\n",
    "                coeff_avg = np.append(coeff_avg, line.coeffs)\n",
    "\n",
    "        coeff_avg = np.vstack(coeff_avg)\n",
    "        return Line(np.mean(coeff_avg, axis=1))\n",
    "    \n",
    "    def getAverageLines(self):\n",
    "        coeff_avg_left = np.array([])\n",
    "        coeff_avg_right = np.array([])\n",
    "        \n",
    "        for line in self.hist_left:\n",
    "            if line.valid:\n",
    "                coeff_avg_left = np.append(coeff_avg_left, line.coeffs)\n",
    "        coeff_avg_left = np.vstack(coeff_avg_left)\n",
    "        left_line = Line(np.mean(coeff_avg_left, axis=1))\n",
    "        \n",
    "        for line in self.hist_right:\n",
    "            if line.valid:\n",
    "                coeff_avg_right = np.append(coeff_avg_right, line.coeffs)\n",
    "        coeff_avg_right = np.vstack(coeff_avg_right)\n",
    "        right_line = Line(np.mean(coeff_avg_right, axis=1))\n",
    "        \n",
    "        return left_line, right_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of corners in x and y direction\n",
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "def cal_get_calib_params():\n",
    "    cal_img_path = \"./camera_cal\"        \n",
    "    img_points = []\n",
    "    obj_points = []\n",
    "\n",
    "    # Object points\n",
    "    objp_template = np.zeros((nx*ny, 3), np.float32)\n",
    "    objp_template[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "        \n",
    "    for imgName in os.listdir(cal_img_path):\n",
    "        #load the image\n",
    "        img = cv2.imread(os.path.join(cal_img_path, imgName))\n",
    "        # convert ot grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "        \n",
    "        if ret == True:\n",
    "            img_points.append(corners)\n",
    "            obj_points.append(objp_template)\n",
    "    return img_points, obj_points\n",
    "        \n",
    "def cal_undistort(img_points, obj_points, img):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, img.shape[1::-1], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Space Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cst_threshold(img, channel='S', thresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    if channel == 'H':\n",
    "        single_channel = hls[:,:,0]\n",
    "    elif channel == 'L':\n",
    "        single_channel = hls[:,:,1]\n",
    "    elif channel == 'S':\n",
    "        single_channel = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(single_channel)\n",
    "    binary_output[(single_channel > thresh[0]) & (single_channel <= thresh[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_mag_thresh(img, sobel_kernel=5, thresh=(0, 255)):\n",
    "    # if the image is a color image, then first convert it to gray\n",
    "    if len(img.shape) > 1:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # calculate the gradient magnitude\n",
    "    mag = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    # scale to a range between 0 and 255\n",
    "    scaled_sobel = np.uint8(255*mag/np.max(mag))\n",
    "    \n",
    "    # apply the threshold and create a binary output image\n",
    "    binary = np.zeros_like(scaled_sobel)\n",
    "    binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_dir_thresh(img, sobel_kernel=5, thresh=(0, np.pi/2)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    sobelx_abs = np.absolute(sobelx)\n",
    "    sobely_abs = np.absolute(sobely)\n",
    "\n",
    "    directions = np.arctan2(sobely_abs, sobelx_abs)\n",
    "\n",
    "    binary = np.zeros_like(directions)\n",
    "    binary[(directions >= thresh[0]) & (directions <= thresh[1])] = 1\n",
    "\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for thresholded binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration\n",
    "img_points, obj_points = cal_get_calib_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_segmentation(img):\n",
    "    # Array of images, which is used to store the intermediate results of the pipeline\n",
    "    plot_img_list = []\n",
    "\n",
    "    #### Parameters ####\n",
    "    # Color thresholds\n",
    "    thresh_cst_h = (90,100)\n",
    "    thresh_cst_l = (200,255)\n",
    "    thresh_cst_s = (150,255)\n",
    "\n",
    "    # Gradient thresholds\n",
    "    # Magnitude\n",
    "    thresh_grad_mag = (100,150)\n",
    "    # Direction\n",
    "    thresh_grad_dir = (0.7,1.3)\n",
    "\n",
    "    # Vertices of ROI mask\n",
    "    x_len = img.shape[1]\n",
    "    y_len = img.shape[0]\n",
    "    vertices = np.array([[[0,y_len],\n",
    "                [int(x_len/2)-30,int(y_len/2)+70],\n",
    "                [int(x_len/2)+30,int(y_len/2)+70],\n",
    "                [x_len,y_len]]])\n",
    "\n",
    "    img_undist = cal_undistort(img_points, obj_points, img)\n",
    "    plot_img_list.append(NamedImage(img_undist, 'Undistortion'))\n",
    "\n",
    "    img_undist = gaussian_smoothing(img, kernel_size=5)\n",
    "\n",
    "    img_color_thresh_H = cst_threshold(img_undist, 'H', thresh_cst_h)\n",
    "    plot_img_list.append(NamedImage(img_color_thresh_H, 'Color Threshold H'))\n",
    "\n",
    "    img_color_thresh_L = cst_threshold(img_undist, 'L', thresh_cst_l)\n",
    "    plot_img_list.append(NamedImage(img_color_thresh_L, 'Color Threshold L'))\n",
    "\n",
    "    img_color_thresh_S = cst_threshold(img_undist, 'S', thresh_cst_s)\n",
    "    plot_img_list.append(NamedImage(img_color_thresh_S, 'Color Threshold S'))\n",
    "\n",
    "    img_grad_mag = grad_mag_thresh(img_undist, 5, thresh_grad_mag)\n",
    "    plot_img_list.append(NamedImage(img_grad_mag, 'Gradient Magnitude Threshold'))\n",
    "\n",
    "    img_grad_dir = grad_dir_thresh(img_undist, sobel_kernel=5, thresh=thresh_grad_dir)\n",
    "    plot_img_list.append(NamedImage(img_grad_dir, 'Gradient Direction Threshold'))\n",
    "\n",
    "    combined_grad = np.zeros_like(img_grad_dir)\n",
    "    combined_grad[((img_grad_mag == 1) & (img_grad_dir == 1))] = 1\n",
    "    plot_img_list.append(NamedImage(combined_grad, 'Combined Gradient Thresholds'))\n",
    "\n",
    "    combined_col = np.zeros_like(img_color_thresh_H)\n",
    "    combined_col[((img_color_thresh_H == 1) | (img_color_thresh_L == 1) | (img_color_thresh_S == 1))] = 1\n",
    "    plot_img_list.append(NamedImage(combined_col, 'Combined Color Thresholds'))\n",
    "\n",
    "    combined = np.zeros_like(img_color_thresh_H)\n",
    "    combined[((combined_grad == 1) | (combined_col == 1))] = 1\n",
    "    plot_img_list.append(NamedImage(combined, 'All Thresholds Combined'))\n",
    "\n",
    "    img_masked = binary_mask(combined, vertices)\n",
    "    plot_img_list.append(NamedImage(img_masked, 'ROI Mask Applied'))\n",
    "\n",
    "    return img_masked, plot_img_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(img, inverse=False):\n",
    "    x_len = img.shape[1]\n",
    "    y_len = img.shape[0]\n",
    "    \n",
    "    src = np.float32([[200,y_len],\n",
    "                      [595,450],\n",
    "                      [686,450],\n",
    "                      [1105,y_len]])\n",
    "    dst = np.float32([[400,y_len],\n",
    "                      [400,0],\n",
    "                      [880,0],\n",
    "                      [880,y_len]])\n",
    "    \n",
    "    #plt.imshow(img)\n",
    "    #plt.plot(src[0][0],src[0][1], '.')\n",
    "    #plt.plot(src[1][0],src[1][1], '.')\n",
    "    #plt.plot(src[2][0],src[2][1], '.')\n",
    "    #plt.plot(src[3][0],src[3][1], '.')\n",
    "    \n",
    "    # in case we want to get the inverse transform, swap src and dst\n",
    "    if inverse:\n",
    "        src,dst = dst,src\n",
    "        \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(img, M, img.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped, M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_init_line_pos(img):\n",
    "    bottom_half = img[img.shape[0]//2:, :]\n",
    "\n",
    "    hist = np.sum(bottom_half, axis = 0)\n",
    "\n",
    "    middle = np.int(hist.shape[0]//2)\n",
    "    \n",
    "    x_left = np.argmax(hist[:middle])\n",
    "    x_right = np.argmax(hist[middle:]) + middle\n",
    "    \n",
    "    return x_left, x_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lines_sliding_win(img, x_init_left, x_init_right):\n",
    "    \n",
    "    out_img = np.dstack((img*255, img*255, img*255))\n",
    "    \n",
    "    num_windows = 9\n",
    "    win_width = 100\n",
    "    min_pix = 50\n",
    "    \n",
    "    win_height = np.int(img.shape[0]//num_windows)\n",
    "    \n",
    "    nonzero = img.nonzero()\n",
    "    nonzero_x = nonzero[1]\n",
    "    nonzero_y = nonzero[0]\n",
    "    \n",
    "    x_current_left = x_init_left\n",
    "    x_current_right = x_init_right\n",
    "    \n",
    "    idx_line_left = []\n",
    "    idx_line_right = []\n",
    "    \n",
    "    for win in range(num_windows):\n",
    "        y_low = img.shape[0] - ((win + 1) * win_height)\n",
    "        y_high = img.shape[0] - (win * win_height)\n",
    "        \n",
    "        x_low_left = x_current_left - win_width\n",
    "        x_high_left = x_current_left + win_width\n",
    "        x_low_right = x_current_right - win_width\n",
    "        x_high_right = x_current_right + win_width\n",
    "        \n",
    "\n",
    "        cv2.rectangle(out_img, (x_low_left, y_low), (x_high_left, y_high), (0,255,0), 5)\n",
    "        cv2.rectangle(out_img, (x_low_right, y_low), (x_high_right, y_high), (0,255,0), 5)\n",
    "        \n",
    "        matching_idx_left = ((nonzero_y >= y_low) & (nonzero_y < y_high) & \\\n",
    "                             (nonzero_x >= x_low_left) & (nonzero_x < x_high_left)).nonzero()[0]\n",
    "        matching_idx_right = ((nonzero_y >= y_low) & (nonzero_y < y_high) & \\\n",
    "                              (nonzero_x >= x_low_right) & (nonzero_x < x_high_right)).nonzero()[0]\n",
    "        \n",
    "        idx_line_left.append(matching_idx_left)\n",
    "        idx_line_right.append(matching_idx_right)\n",
    "        \n",
    "        if len(matching_idx_left) > min_pix:\n",
    "            x_current_left = np.int(np.mean(nonzero_x[matching_idx_left]))\n",
    "        if len(matching_idx_right) > min_pix:\n",
    "            x_current_right = np.int(np.mean(nonzero_x[matching_idx_right]))\n",
    "            \n",
    "    idx_line_left = np.concatenate(idx_line_left)\n",
    "    idx_line_right = np.concatenate(idx_line_right)\n",
    "    \n",
    "    x_left = nonzero_x[idx_line_left]\n",
    "    y_left = nonzero_y[idx_line_left]\n",
    "    x_right = nonzero_x[idx_line_right]\n",
    "    y_right = nonzero_y[idx_line_right]\n",
    "    \n",
    "    return x_left, y_left, x_right, y_right, out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_polynomial(img):\n",
    "    \n",
    "    # Find the starting positions for the window search\n",
    "    x_init_left, x_init_right = find_init_line_pos(img)\n",
    "    \n",
    "    # Search the lines with sliding windows\n",
    "    x_left, y_left, x_right, y_right, out_img_rect = find_lines_sliding_win(img, x_init_left, x_init_right)\n",
    "    \n",
    "    # Fit a second order polynomial through the marked pixels\n",
    "    line_left = Line(np.polyfit(y_left, x_left, 2), x_left, y_left)\n",
    "    line_right = Line(np.polyfit(y_right, x_right, 2), x_right, y_right)\n",
    "    \n",
    "    out_img_rect[y_left, x_left] = [255,0,0]\n",
    "    out_img_rect[y_right, x_right] = [0,0,255]\n",
    "    \n",
    "    out_img = np.zeros_like(out_img_rect)\n",
    "    out_img[y_left, x_left] = [255,0,0]\n",
    "    out_img[y_right, x_right] = [0,0,255]\n",
    "    \n",
    "    return out_img, out_img_rect, line_left, line_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lane_area(img_shape, line_left, line_right):\n",
    "    lane_area = np.zeros(img_shape)\n",
    "    \n",
    "    y_plot = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    x_plot_left = line_left.f(y_plot)\n",
    "    x_plot_right = line_right.f(y_plot)\n",
    "    \n",
    "    for row in range(img_shape[0]):\n",
    "        for col in range(img_shape[1]):\n",
    "            if (x_plot_left[row] <= col) & (col <= x_plot_right[row]):\n",
    "                lane_area[row, col] = [0,255,0]\n",
    "                \n",
    "    return lane_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Segment the lane lines and get a binary image\n",
    "    binary, _ = line_segmentation(img)\n",
    "\n",
    "    # Warp the image to birdseye view\n",
    "    warped, _ = perspective_transform(binary)\n",
    "\n",
    "    # Fit polynomials through the lane lines\n",
    "    img_poly_fit, _, line_left, line_right = fit_polynomial(warped)\n",
    "    \n",
    "    ###############\n",
    "    ### DRAWING ###\n",
    "    ###############\n",
    "    \n",
    "    # Unwarp the image, that marks the lane lines\n",
    "    unwarped_lines, _ = perspective_transform(img_poly_fit, inverse=True)\n",
    "    # Unwarp the image, that marks the lane area\n",
    "    img_lane_area = draw_lane_area(img.shape, line_left, line_right)\n",
    "    unwarped_area, _ = perspective_transform(img_lane_area, inverse=True)\n",
    "\n",
    "    # Combine the results with the original image\n",
    "    img = combine_img(img, unwarped_area, alpha=0.8, beta=.5, gamma=0.)\n",
    "    img[unwarped_lines[:,:,0] == 255] = [255,0,0]\n",
    "    img[unwarped_lines[:,:,2] == 255] = [0,0,255]\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    plt.text(100,100,str(line_left.radius_m(img.shape[0])),withdash=True)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgProcessor():\n",
    "    def __init__(self):\n",
    "        self.lineHist = LineHist()\n",
    "        \n",
    "    def process_image(self, img):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Segment the lane lines and get a binary image\n",
    "        binary, _ = line_segmentation(img)\n",
    "\n",
    "        # Warp the image to birdseye view\n",
    "        warped, _ = perspective_transform(binary)\n",
    "\n",
    "        # Fit polynomials through the lane lines\n",
    "        img_poly_fit, _, line_left, line_right = fit_polynomial(warped)\n",
    "        \n",
    "        print(line_left.coeffs)\n",
    "        print(line_right.coeffs)\n",
    "        \n",
    "        self.lineHist.appendLines(line_left, line_right)\n",
    "\n",
    "        line_left, line_right = self.lineHist.getAverageLines()\n",
    "        \n",
    "        ###############\n",
    "        ### DRAWING ###\n",
    "        ###############\n",
    "        \n",
    "        # Unwarp the image, that marks the lane lines\n",
    "        unwarped_lines, _ = perspective_transform(img_poly_fit, inverse=True)\n",
    "        # Unwarp the image, that marks the lane area\n",
    "        img_lane_area = draw_lane_area(img.shape, line_left, line_right)\n",
    "        unwarped_area, _ = perspective_transform(img_lane_area, inverse=True)\n",
    "        #plt.imshow(img_lane_area)\n",
    "\n",
    "        print(type(img))\n",
    "        print(type(unwarped_area))\n",
    "        print(len(self.lineHist.hist_left))\n",
    "        print(len(self.lineHist.hist_right))\n",
    "        print(self.lineHist.hist_right[0].valid)\n",
    "        print(self.lineHist.hist_right[1].valid)\n",
    "        \n",
    "        # Combine the results with the original image\n",
    "        #img = combine_img(img, unwarped_area, alpha=0.8, beta=.5, gamma=0.)\n",
    "        img[unwarped_lines[:,:,0] == 255] = [255,0,0]\n",
    "        img[unwarped_lines[:,:,2] == 255] = [0,0,255]\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        plt.text(100,100,str(line_left.radius_m(img.shape[0])),withdash=True)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3.08871773e-04   4.43544737e-01   2.88814167e+02]\n",
      "[ -2.92925876e-04   4.31924903e-01   7.67361085e+02]\n",
      "Called appendLines()\n",
      "sanityCheck failed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-ad46e48bef8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-ad46e48bef8d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# load test image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_images/test2.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-5115cb46fd3f>\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineHist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappendLines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mline_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineHist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAverageLines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m###############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-243d971faaad>\u001b[0m in \u001b[0;36mgetAverageLines\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mcoeff_avg_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoeff_avg_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mcoeff_avg_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoeff_avg_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mleft_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoeff_avg_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    img_proc = ImgProcessor()\n",
    "    # load test image\n",
    "    img = cv2.imread('test_images/test2.jpg')\n",
    "    img = img_proc.process_image(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_output = './output_video/project_video.mp4'\n",
    "clip1 = VideoFileClip(\"./project_video.mp4\").subclip(0,5)\n",
    "video_clip = clip1.fl_image(process_image)\n",
    "%time video_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
